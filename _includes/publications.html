<div class="row g-5 mb-5">
  <div>
    <h3 class="fw-bold border-bottom pb-3 mb-5">Research</h3>
    <ul>
      <li><b>Active Learning of Deep Neural Networks via Gradient-Free Cutting Planes</b>   <br><span style="color:#909497">Erica Zhang<sup>*</sup> </span>, <b>Fangzhao Zhang<sup>*</sup></b>,  <span style="color:#909497"> Mert Pilanci</span> <br> <span style="color:#909497">Preprint 2024</span> <br><a href="https://arxiv.org/abs/2410.02145">[paper]</a></br> </li>
      <br>
      <li><b>Newton Meets Marchenko-Pastur: Massively Parallel Second-Order Optimization with Hessian Sketching and Debiasing</b>  <br><span style="color:#909497">Elad Romanov</span>, <b>Fangzhao Zhang</b>,  <span style="color:#909497">Mert Pilanci</span> <br> <span style="color:#909497">International Conference on Learning Representations (<span style="color:#17202A"><b>ICLR</b></span>) 2025</span> <br><a href="https://arxiv.org/abs/2410.01374">[paper]</a></br> </li>
      <br>
      <li><b>Spectral Adapter: Fine-Tuning in Spectral Space</b>  <br> <b>Fangzhao Zhang</b>,  <span style="color:#909497">Mert Pilanci</span> <br> <span style="color:#909497">Conference on Neural Information Processing System (<span style="color:#17202A"><b>NeurIPS</b></span>) 2024</span> <br><a href="https://arxiv.org/abs/2405.13952">[paper]</a> <a href="https://github.com/pilancilab/spectral_adapter">[code]</a></br> </li>
      <br>
      <li><b>Riemannian Preconditioned LoRA for Fine-Tuning Foundation Models</b>  <br> <b>Fangzhao Zhang</b>, <span style="color:#909497"> Mert Pilanci</span> <br> <span style="color:#909497">International Conference on Machine Learning (<span style="color:#17202A"><b>ICML</b></span>) 2024</span> <br><a href="https://arxiv.org/abs/2402.02347">[paper]</a> <a href="https://github.com/pilancilab/Riemannian_Preconditioned_LoRA">[code]</a></br> </li>
      <br>
      <li><b>Analyzing Neural Network-Based Generative Diffusion Models through Convex Optimization</b>   <br> <b>Fangzhao Zhang</b>,  <span style="color:#909497">Mert Pilanci</span> <br> <span style="color:#909497">Preprint 2024</span> <br><a href="https://arxiv.org/abs/2402.01965">[paper]</a></br> </li>
      <br>
      <li><b>Optimal Shrinkage for Distributed Second-Order Optimization </b>   <br> <b>Fangzhao Zhang</b>,  <span style="color:#909497">Mert Pilanci</span> <br> <span style="color:#909497">International Conference on Machine Learning (<span style="color:#17202A"><b>ICML</b></span>) 2023</span> <br><a href="https://arxiv.org/abs/2402.01956">[paper]</a></br> </li>
      <br>
      <li><b>Implementation of an Oracle-Structured Bundle Method for Distributed Optimization</b>  <br><span style="color:#909497">Tetiana Parshakova</span>, <b>Fangzhao Zhang</b>,  <span style="color:#909497">Stephen Boyd</span> <br> <span style="color:#909497">Optimization and Engineering 2023</span>  <br><a href="https://arxiv.org/abs/2211.01418">[paper]</a> <a href="https://github.com/cvxgrp/OSBDO">[code]</a></br> </li>
    </ul>
    (<sup>*</sup> indicates equal contribution)
  </div>
</div>
